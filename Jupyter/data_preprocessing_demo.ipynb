{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9701393e",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde1720",
   "metadata": {},
   "source": [
    "We will create our own daa example set with keras. the data consists of a clinical trial conducted on 2100 patients ranging from \n",
    "ages 13 to 100 with half the patients under 65 and the other half over 65 years of age.\n",
    "We want to find the possibility of a patient experoencing side effects due to thier age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33a66e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f88e5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39614894",
   "metadata": {},
   "source": [
    "CREATING A RANDOM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "694eefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    #the 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "\n",
    "    #the 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    #the 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "\n",
    "    #the 5% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50120da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 75, 49, 85, 30]\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "#printing random samples that we created above(only first 5)\n",
    "print(train_samples[:5])\n",
    "#print total train_samples\n",
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99065115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1]\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "#printing train labels that we created above(only first 5)\n",
    "print(train_labels[:5])\n",
    "#print total train_labels\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b6a7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the train_labels and the train_samples intp an numpy array\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "#we can shuffle to randomize the data\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "548b0909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44827586],\n",
       "       [0.91954023],\n",
       "       [0.24137931],\n",
       "       [0.44827586],\n",
       "       [0.45977011]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have to convert the data between 0 and 1 otherwise we create a bias\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples= scaler.fit_transform(train_samples.reshape(-1,1))\n",
    "scaled_train_samples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d4db1",
   "metadata": {},
   "source": [
    "CREATING AN ARTIFICIAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5eb1d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2551000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 16, input_shape=(1,), activation = 'relu'),\n",
    "    Dense(units = 32 , activation = 'relu'),\n",
    "    Dense(units = 2, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c1cf4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                32        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc9f15",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11b8d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= Adam(learning_rate = 0.001), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7fb56f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 2s - loss: 0.5870 - accuracy: 0.7122 - val_loss: 0.4737 - val_accuracy: 0.8333 - 2s/epoch - 9ms/step\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.3490 - accuracy: 0.9021 - val_loss: 0.3151 - val_accuracy: 0.9143 - 375ms/epoch - 2ms/step\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.2690 - accuracy: 0.9270 - val_loss: 0.3078 - val_accuracy: 0.8952 - 366ms/epoch - 2ms/step\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.2540 - accuracy: 0.9354 - val_loss: 0.2984 - val_accuracy: 0.9286 - 288ms/epoch - 2ms/step\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.2454 - accuracy: 0.9370 - val_loss: 0.2985 - val_accuracy: 0.9143 - 318ms/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.2422 - accuracy: 0.9450 - val_loss: 0.2910 - val_accuracy: 0.9381 - 301ms/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.2390 - accuracy: 0.9460 - val_loss: 0.2920 - val_accuracy: 0.9143 - 299ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.2371 - accuracy: 0.9392 - val_loss: 0.2863 - val_accuracy: 0.9286 - 300ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.2335 - accuracy: 0.9450 - val_loss: 0.2854 - val_accuracy: 0.9286 - 316ms/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.2321 - accuracy: 0.9381 - val_loss: 0.2877 - val_accuracy: 0.9286 - 317ms/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.2326 - accuracy: 0.9402 - val_loss: 0.2846 - val_accuracy: 0.9238 - 317ms/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.2304 - accuracy: 0.9444 - val_loss: 0.2810 - val_accuracy: 0.9381 - 314ms/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.2296 - accuracy: 0.9497 - val_loss: 0.2831 - val_accuracy: 0.9286 - 317ms/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.2294 - accuracy: 0.9418 - val_loss: 0.2803 - val_accuracy: 0.9381 - 302ms/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.2289 - accuracy: 0.9492 - val_loss: 0.2780 - val_accuracy: 0.9381 - 316ms/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.2287 - accuracy: 0.9471 - val_loss: 0.2815 - val_accuracy: 0.9238 - 317ms/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.2294 - accuracy: 0.9418 - val_loss: 0.2765 - val_accuracy: 0.9381 - 317ms/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2267 - accuracy: 0.9481 - val_loss: 0.2817 - val_accuracy: 0.9286 - 316ms/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2269 - accuracy: 0.9460 - val_loss: 0.2762 - val_accuracy: 0.9381 - 315ms/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2268 - accuracy: 0.9434 - val_loss: 0.2757 - val_accuracy: 0.9286 - 301ms/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2255 - accuracy: 0.9481 - val_loss: 0.2738 - val_accuracy: 0.9286 - 304ms/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2239 - accuracy: 0.9476 - val_loss: 0.2730 - val_accuracy: 0.9286 - 302ms/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2233 - accuracy: 0.9487 - val_loss: 0.2732 - val_accuracy: 0.9238 - 298ms/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2227 - accuracy: 0.9497 - val_loss: 0.2738 - val_accuracy: 0.9286 - 315ms/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2228 - accuracy: 0.9444 - val_loss: 0.2709 - val_accuracy: 0.9381 - 317ms/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2211 - accuracy: 0.9487 - val_loss: 0.2696 - val_accuracy: 0.9286 - 316ms/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2209 - accuracy: 0.9503 - val_loss: 0.2693 - val_accuracy: 0.9381 - 316ms/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2213 - accuracy: 0.9455 - val_loss: 0.2698 - val_accuracy: 0.9286 - 300ms/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2203 - accuracy: 0.9466 - val_loss: 0.2685 - val_accuracy: 0.9286 - 301ms/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2198 - accuracy: 0.9455 - val_loss: 0.2675 - val_accuracy: 0.9381 - 318ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bfb3f0dc70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, validation_split = 0.1, batch_size=10, shuffle=True, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fafdb",
   "metadata": {},
   "source": [
    "BUILDING A TEST SET AND PREDICTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65ddd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cedbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    #the 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "\n",
    "    #the 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    #the 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "\n",
    "    #the 5% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "scaled_test_samples= scaler.fit_transform(test_samples.reshape(-1,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2972412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict( x=scaled_test_samples, batch_size=10 , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1852c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06581298 0.934187  ]\n",
      " [0.9341335  0.06586648]\n",
      " [0.9665808  0.03341918]\n",
      " [0.9673518  0.03264814]\n",
      " [0.9487827  0.05121731]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6a68b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rounding off the predictions to get b/w 0 and 1\n",
    "rounded_predictions = np.argmax(predictions, axis= -1)\n",
    "rounded_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f4443",
   "metadata": {},
   "source": [
    "CONFUSION MATRIX FOR ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af4b3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "657d95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  50]\n",
      " [ 50 200]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true = test_labels, y_pred = rounded_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30256743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion Matrix',\n",
    "                          cmap = plt.cm.Blues):\n",
    "    \"\"\" THIS FUNCTION PRINTS AND PLOTS THE CONFUSION MATRIX,\n",
    "        NORMALIZATION CAN BE APPLIED BY SETTING normalization = True \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arrange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm=cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "        horizontalalignment=\"center\",\n",
    "        color= \"white\" if cm[i, j] > thresh else \"black\" )\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
